# A Simple Example of Using Claude Code with Our Dataset

This is an example program that uses **Claude Code** to perform automated code review on GitHub Pull Requests from the AACR-Bench dataset.

## ğŸ“‹ Overview

This example demonstrates how to perform code review on real open-source project PRs through the Claude Code API. The main features include:

- Automatically clone and switch to target PR branches
- Configure code review Agent
- Execute automatic review of code changes
- Collect and save review comments

This example is for reference only and shows how to use our dataset. Please replace with your own code review agent for actual evaluation.

## ğŸ“ Structure

```
claude-code-demo/
â”œâ”€â”€ main.py                 # Main program entry point
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.json        # Configuration file (Claude CLI path, dataset path)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ claude_code_util.py  # Claude Code utility functions
â”‚   â”œâ”€â”€ git_util.py          # Git operation utilities
â”‚   â”œâ”€â”€ dataset_util.py      # Dataset loading and parsing
â”‚   â”œâ”€â”€ constants_util.py    # Constant definitions (prompt templates, etc.)
â”‚   â””â”€â”€ model.py             # Data model definitions
â”œâ”€â”€ .claude/
â”‚   â””â”€â”€ agents/
â”‚       â””â”€â”€ code-reviewer.md # Code review Agent configuration
â”œâ”€â”€ comments/               # Review result storage directory
â””â”€â”€ README.md              # This file
```

## ğŸ”§ Core Module Description

### 1. main.py - Main Program
- `load_data_as_task()`: Convert raw dataset to task format
- `run_claude_code()`: Execute complete review process for a single PR
- `main()`: Main loop, batch process all PRs and track progress
- `copy_comments()`: Extract and save comments generated by Claude Code

### 2. utils/ Utility Modules

#### claude_code_util.py
- `get_claude_code_options()`: Configure Claude Code runtime parameters
- `add_code_review_agent()`: Create code review Agent
- `load_config()`: Load configuration file

#### git_util.py
- `git_clone()`: Clone Git repository locally
- `checkout()`: Switch to specified PR branch
- `git_fetch()`: Fetch specified commit

#### dataset_util.py
- `load_dataset()`: Load dataset from JSON file
- `get_gitrepo_pr_id()`: Parse repository and PR ID from PR URL

#### constants_util.py
- `BASE_PROMPT`: Code review prompt template

## ğŸš€ Quick Start

### 1. Environment Preparation

Ensure the following dependencies are installed:
```bash
pip install claude-agent-sdk anyio tqdm
```

### 2. Configure Claude CLI

Edit `configs/config.json` and set the installation path of Claude CLI:

```json
{
  "cli_path": "C:\\Users\\YourName\\AppData\\Roaming\\npm\\claude.cmd",
  "data_path": "C:\\path\\to\\your\\dataset\\positive_samples.json"
}
```

### 3. Prepare Dataset

For the first run, you need to convert the raw data to task format. Uncomment and run in `main.py`:

```python
if __name__ == "__main__":
    load_data_as_task()  # First run: generate task file
    # main()              # Formal run: execute review tasks
```

This will:
- Read the raw dataset (file specified by `data_path`)
- Add `finish` flag to each PR for tracking progress
- Generate `tmp_data.json` task file

### 4. Run Code Review

```bash
cd claude-code-demo
python main.py
```

The program will automatically:
1. Load the task dataset
2. Process each PR one by one (skip completed ones)
3. Clone repository and switch to target branch
4. Call Claude Code for code review
5. Save review comments to `comments/` directory
6. Wait 30 seconds after completing each task (avoid network restrictions)
7. Real-time save progress to `tmp_data.json`

## ğŸ“Š Data Format

### Input Dataset Format

```json
{
  "githubPrUrl": "https://github.com/owner/repo/pull/123",
  "source_commit": "abc123...",
  "target_commit": "def456...",
  "change_line_count": 100,
  "project_main_language": "Python",
  "finish": false
}
```

### Field Description
- `githubPrUrl`: Full URL of GitHub Pull Request
- `source_commit`: Source commit hash of the PR
- `target_commit`: Target commit hash of the PR
- `change_line_count`: Number of changed code lines
- `project_main_language`: Main programming language of the project
- `finish`: Task completion flag (automatically maintained by the program)

### Review Result Format

Review results are saved in the `comments/` directory with the naming format:
```
comments_{repo_name}_{pr_id}.txt
```

For example: `comments_FreeCAD_18688.txt`

The file content contains code review comments generated by Claude Code, including:
- Issue findings
- Improvement suggestions
- Code quality assessment

## ğŸ”„ Workflow

```
1. Load dataset (tmp_data.json)
   â†“
2. Clone repository locally (repos/ directory)
   â†“
3. Switch to PR branch
   â†“
4. Get source and target commit
   â†“
5. Create code review Agent
   â†“
6. Call Claude Code to review code changes
   â†“
7. Extract review comments
   â†“
8. Save to comments/ directory
   â†“
9. Mark task as completed
   â†“
10. Continue to next PR
   â†“
11. Get comments
   â†“
12. Start eval(evaluator_runner/example_test.py)
```

## âš™ï¸ Configuration Description

### Claude Code Agent

`.claude/agents/code-reviewer.md` defines the behavior and rules for code review, including:
- Review focus (security, performance, maintainability, etc.)
- Output format requirements
- Context usage strategy

### Prompt Template

`BASE_PROMPT` in `utils/constants_util.py` defines the prompt sent to Claude Code

## ğŸ“ Notes

1. **Network Restrictions**: The program will wait 30 seconds after completing each task to avoid triggering API limits
2. **Progress Recovery**: The program will automatically skip tasks marked as `finish: true`, supporting resumption after interruption
3. **Disk Space**: Cloned repositories will be saved in the `repos/` directory, please ensure sufficient disk space
4. **Claude CLI**: Ensure Claude CLI is properly installed and configured with a valid API key

## ğŸ“š Extended Usage

### Custom Review Rules
Edit `.claude/agents/code-reviewer.md` to customize review focus and output format.

### Batch Processing
Modify the loop logic in `main.py` to add parallel processing, filter specific languages, and other features.

### Result Analysis
Use the result files in the `comments/` directory for further statistical analysis and model evaluation.
